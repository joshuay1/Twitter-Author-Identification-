{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import pandas as pd\n",
    "import re\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions for feature engineering\n",
    "\n",
    "- Number of special characters (done)\n",
    "- Number of words per tweet\n",
    "- Number of characters per tweet\n",
    "- Number of characters\n",
    "- Average word length (done)\n",
    "- Ratio of stopwords (done)\n",
    "- Existence of handle (done)\n",
    "- Existence of link  (done)\n",
    "- IsRetweet 'RT' (done)\n",
    "- Number of uppercase words (done)\n",
    "- Remove hashtag (done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(data_line):\n",
    "    hashtag=r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\" # hash-tags\n",
    "    data_line = re.sub(hashtag, \"\", data_line)\n",
    "    data_line = re.sub(r'http\\S+', 'http', data_line)\n",
    "    data_line = data_line.replace(\"@handle\",\"handle\")\n",
    "    data_line = data_line.replace(\"\\n\",\"\")\n",
    "    data_line = data_line.split(\"\\t\")\n",
    "    return data_line\n",
    "\n",
    "def get_stopword_ratio(data_line):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(data_line)\n",
    "    stop_word_list = [w for w in word_tokens if w in stop_words]\n",
    "    return len(stop_word_list)/len(word_tokens)\n",
    "  \n",
    "def is_RT(tweet_line):\n",
    "    if len(tweet_line) > 0: \n",
    "        return tweet_line.split(\" \")[0] == \"RT\"\n",
    "    return False\n",
    "        \n",
    "    \n",
    "def is_modifiedRT(tweet_line):\n",
    "    if is_RT(tweet_line):\n",
    "        return False\n",
    "    elif (re.search(r'RT @handle', tweet_line)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "      \n",
    "def get_ratio_emoticon(tweet_line):\n",
    "    emoticons_str = r\"[:=;xX][oO0\\-]?[dD\\)\\]\\(\\]/\\\\o0OpP]\"\n",
    "    emo_puc = r\"[!+?+]\"\n",
    "    emo_list = re.findall(emoticons_str, tweet_line)\n",
    "    emo_list += re.findall(emo_puc, tweet_line)\n",
    "    return len(emo_list)/len(tweet_line)\n",
    "  \n",
    "def get_average_word_length(data_line):\n",
    "    words = data_line.split()\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "  \n",
    "def get_ratio_upper_characters(data_line):\n",
    "    u = [x for x in data_line if x.isupper()]\n",
    "    return len(u)/len(data_line)\n",
    "  \n",
    "def get_ratio_special_characters(data_line):\n",
    "    return sum([data_line.count(i) for i in [\"!\",\"?\"]])/len(data_line)\n",
    "  \n",
    "def get_num_words(data_line):\n",
    "    return len(data_line.split())  \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "We read in the data line by line. The above helper functions are you used create features.\n",
    "\n",
    "First we define list of features then in the last step we put it all together in a dataframe. It is about 10x faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prep(tweets_file):\n",
    "    author_Id = [] \n",
    "    tweet = [] \n",
    "    num_words =  [] \n",
    "    ratio_spec_char = []\n",
    "    ratio_stopwords = []\n",
    "    ratio_upper = []\n",
    "    average_word_length = []\n",
    "    is_retweet = []\n",
    "    is_modified_retweet = [] \n",
    "    ratio_emoticon = [] \n",
    "\n",
    "    with open(tweets_file, \"r\") as file:\n",
    "        for i in file:\n",
    "            data_line = i\n",
    "            author_Id.append( int(data_preprocess(data_line)[0]))\n",
    "            tweet.append( data_preprocess(data_line)[1])\n",
    "            num_words.append(  get_num_words(data_line))\n",
    "            ratio_spec_char.append( get_ratio_special_characters(data_line))\n",
    "            ratio_stopwords.append( get_stopword_ratio(data_line))\n",
    "            ratio_upper.append( get_ratio_upper_characters(data_line))\n",
    "            average_word_length.append( get_average_word_length(data_line))\n",
    "            is_retweet.append( is_RT(data_line))\n",
    "            is_modified_retweet.append( is_modifiedRT(data_line))\n",
    "            ratio_emoticon.append( get_ratio_emoticon(data_line))\n",
    "\n",
    "    df = pd.DataFrame({'author_Id':author_Id,\n",
    "                       'tweet':tweet,\n",
    "                       'num_words':num_words,\n",
    "                       'ratio_spec_char':ratio_spec_char,\n",
    "                       'ratio_stopwords':ratio_stopwords,\n",
    "                       'ratio_upper':ratio_upper,\n",
    "                       'average_word_length':average_word_length,\n",
    "                       'is_retweet':is_retweet,\n",
    "                       'is_modified_retweet':is_modified_retweet,\n",
    "                       'ratio_emoticon':ratio_emoticon})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "clean_train_data = read_prep(\"data/train_tweets.txt\")\n",
    "y = clean_train_data.author_Id\n",
    "X = clean_train_data.drop('author_Id', axis=1)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.25, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246699\n",
      "82233\n",
      "246699\n",
      "82233\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(y_train))\n",
    "print(len(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train],axis=1)\n",
    "dev_data = pd.concat([X_dev, y_dev],axis=1)\n",
    "train_data.to_csv(\"data/train_data.csv\")\n",
    "dev_data.to_csv(\"data/dev_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "                                                    tweet  num_words  \\\n",
      "236809  handle I miss you Hun. I've been grindin. Imma...         26   \n",
      "199574  handle Oh it happened...I saw the belt on the ...         21   \n",
      "158427  won a signed poster and tkts to handle at hand...         20   \n",
      "256458                             I want Lisa's earrings          5   \n",
      "201048                            handle Wellllll... http          4   \n",
      "\n",
      "        ratio_spec_char  ratio_stopwords  ratio_upper  average_word_length  \\\n",
      "236809         0.000000         0.285714     0.059701             4.153846   \n",
      "199574         0.000000         0.333333     0.026549             4.380952   \n",
      "158427         0.009434         0.259259     0.018868             4.300000   \n",
      "256458         0.000000         0.000000     0.076923             4.200000   \n",
      "201048         0.000000         0.000000     0.086957            10.500000   \n",
      "\n",
      "        is_retweet  is_modified_retweet  ratio_emoticon  \n",
      "236809       False                False        0.014925  \n",
      "199574       False                False        0.000000  \n",
      "158427       False                False        0.009434  \n",
      "256458       False                False        0.000000  \n",
      "201048       False                False        0.021739  \n",
      "\n",
      "y_train:\n",
      "\n",
      "236809    8995\n",
      "199574    6984\n",
      "158427    6544\n",
      "256458      79\n",
      "201048    5814\n",
      "Name: author_Id, dtype: int64\n",
      "\n",
      "train_data:\n",
      "\n",
      "                                                    tweet  num_words  \\\n",
      "236809  handle I miss you Hun. I've been grindin. Imma...         26   \n",
      "199574  handle Oh it happened...I saw the belt on the ...         21   \n",
      "158427  won a signed poster and tkts to handle at hand...         20   \n",
      "256458                             I want Lisa's earrings          5   \n",
      "201048                            handle Wellllll... http          4   \n",
      "\n",
      "        ratio_spec_char  ratio_stopwords  ratio_upper  average_word_length  \\\n",
      "236809         0.000000         0.285714     0.059701             4.153846   \n",
      "199574         0.000000         0.333333     0.026549             4.380952   \n",
      "158427         0.009434         0.259259     0.018868             4.300000   \n",
      "256458         0.000000         0.000000     0.076923             4.200000   \n",
      "201048         0.000000         0.000000     0.086957            10.500000   \n",
      "\n",
      "        is_retweet  is_modified_retweet  ratio_emoticon  author_Id  \n",
      "236809       False                False        0.014925       8995  \n",
      "199574       False                False        0.000000       6984  \n",
      "158427       False                False        0.009434       6544  \n",
      "256458       False                False        0.000000         79  \n",
      "201048       False                False        0.021739       5814  \n"
     ]
    }
   ],
   "source": [
    "print('\\nX_train:\\n')\n",
    "print(X_train.head())\n",
    "print('\\ny_train:\\n')\n",
    "print(y_train.head())\n",
    "print('\\ntrain_data:\\n')\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
